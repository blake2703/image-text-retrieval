{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2392314b",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "**Note: Please include a `requirements.txt` file in the future**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a53b7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from torchvision import transforms\n",
    "import torchvision.transforms.functional as F \n",
    "from torchvision.models import vgg16\n",
    "\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35a1cfab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    print(\"No GPU found\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a072be5d",
   "metadata": {},
   "source": [
    "## Part 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21327186",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "**Note: move the `results.csv` file into the cloned repository and the below cell will run**\n",
    "\n",
    "1. We want to have two versions `data_raw` will be the untouched dataset and `data_copy` will be the one we do manipulations on \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054189d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_raw = pd.read_csv(f\"{os.getcwd()}/results.csv\",\n",
    "                       delimiter=\"|\")\n",
    "data_copy = data_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346a0c9c",
   "metadata": {},
   "source": [
    "### Data cleaning and info\n",
    "1. Call .info() to generate the non-null counts, the column name, and the data type of each column\n",
    "    - There is whitespace in `comment_number` and `comment` column names\n",
    "    - There is a null value in the `comment` column\n",
    "2. Verify there is 5 comments for each image\n",
    "3. Call .describe() to generate basic statistics about the data\n",
    "    - There is one more unique comment number in the `comment_number` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95944892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 158915 entries, 0 to 158914\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   image_name       158915 non-null  object\n",
      " 1    comment_number  158915 non-null  object\n",
      " 2    comment         158914 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_copy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ae08f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:  Index(['image_name', ' comment_number', ' comment'], dtype='object')\n",
      "After cleaning:  Index(['image_name', 'comment_number', 'comment'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Before cleaning: \", data_copy.columns)\n",
    "data_copy.columns = data_copy.columns.str.replace(' ', '')\n",
    "print(\"After cleaning: \", data_copy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc84983",
   "metadata": {},
   "source": [
    "The data is structured into three columns:\n",
    "1. **image_name**: represents the image that the comments are attached to\n",
    "2. **comment_number**: the comment number associated with the image\n",
    "3. **comment**: the actual comment of the image\n",
    "\n",
    "We should expect to see 5 comments for each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f96ac768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length of unique values:  31783\n",
      "Total length of data frame:  158915\n",
      "Total length of unique values with comments: 158915\n"
     ]
    }
   ],
   "source": [
    "image_name_unique_vals = data_copy['image_name'].unique().tolist()\n",
    "print(\"Total length of unique values: \", len(image_name_unique_vals))\n",
    "print(\"Total length of data frame: \",  len(data_raw))\n",
    "print(\"Total length of unique values with comments:\", len(image_name_unique_vals) * 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35ab6159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_name</th>\n",
       "      <td>158915</td>\n",
       "      <td>31783</td>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment_number</th>\n",
       "      <td>158915</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>31783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comment</th>\n",
       "      <td>158914</td>\n",
       "      <td>158438</td>\n",
       "      <td>Two dogs playing in the snow .</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count  unique                              top   freq\n",
       "image_name      158915   31783                   1000092795.jpg      5\n",
       "comment_number  158915       6                                0  31783\n",
       "comment         158914  158438   Two dogs playing in the snow .      7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcbb8751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 0', ' 1', ' 2', ' 3', ' 4', ' 4   A dog runs across the grass .']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_number_unique_vals = data_copy['comment_number'].unique().tolist()\n",
    "comment_number_unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7c5a0566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '4Adogrunsacrossthegrass.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy['comment_number'] = data_copy['comment_number'].str.replace('\\s+', '', regex=True)\n",
    "comment_number_unique_vals = data_copy['comment_number'].unique().tolist()\n",
    "comment_number_unique_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe74ec0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>2199200615.jpg</td>\n",
       "      <td>4Adogrunsacrossthegrass.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           image_name            comment_number comment\n",
       "19999  2199200615.jpg  4Adogrunsacrossthegrass.     NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy[data_copy.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2e8936e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_name                      2199200615.jpg\n",
       "comment_number                               4\n",
       "comment           A dog runs across the grass.\n",
       "Name: 19999, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.loc[19999, 'image_name'] = '2199200615.jpg'\n",
    "data_copy.loc[19999, 'comment_number'] = '4'\n",
    "data_copy.loc[19999, 'comment'] = 'A dog runs across the grass.'\n",
    "data_copy.iloc[19999]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db921c50",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "1. Preprocess text and make a new column with cleaned text\n",
    "    - Remove whitespace\n",
    "    - Remove punctuation\n",
    "    - Expand contractions\n",
    "    - Make everything lowercase\n",
    "    - Remove stopwords\n",
    "    - Lemmatize words that are needed\n",
    "2. Encode text for BERT\n",
    "    - Get the max length of the comments in the dataset\n",
    "    - Generate the input_ids and the attention masks for each comment in the dataset\n",
    "        - Add these as columns into the dataset\n",
    "3. Preprocess images\n",
    "    - Turn each image path into a column in the dataset\n",
    "    - Resize each image to (224 x 224)\n",
    "    - Use a standard mean and std \n",
    "    - Turn each image to a tensor\n",
    "4. Get VGG16 embeddings\n",
    "    - Extract the classifiaction layer from vgg16\n",
    "    - Take the first 500 rows -> 100 images\n",
    "    - Put the embeddings in a new column\n",
    "5. Get BERT embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6cb9c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data_copy[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98cfa5a",
   "metadata": {},
   "source": [
    "#### Preprocess Text\n",
    "1. Remove whitespace from each comment\n",
    "2. Remove all punctuations from each comment\n",
    "3. Expand contractions \n",
    "4. Turn all comments to lower case\n",
    "5. Tokenize each word -> i.e. turn comment into a list of substrings for each word\n",
    "    - comment: \"I like dogs\" -> ['I', 'like', 'dogs']\n",
    "6. Use the tokenizing of the words to remove `stopwords`\n",
    "    - A `stopword` is a common occuring word. Words such as 'a' and 'is' are examples of a `stopword`\n",
    "    - Get a set of English stopwords to remove common words like 'the', 'is', etc.\n",
    "7. Lemmatize the words\n",
    "    - A `lemmatizer` takes a word and turns it into its lemma\n",
    "    - For example, if we have the words 'walking', 'walked' and 'walks' the words would now become 'walk'\n",
    "\n",
    "8. Return the comment\n",
    "    - Each comment is turned into its own string and returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad0d7664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_comment(comment):\n",
    "    '''\n",
    "    Preprocess the ith row and jth comment\n",
    "    \n",
    "    @comment: the comment that is getting preprocessed\n",
    "    '''\n",
    "    comment = comment.strip()\n",
    "    comment = comment.translate(str.maketrans('', '', string.punctuation))\n",
    "    comment = contractions.fix(comment)\n",
    "    comment = comment.lower()\n",
    "    words = word_tokenize(comment)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word.lower() not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    processed_comment = ' '.join(words)\n",
    "    return processed_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "200726a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>A little girl in a pink dress going into a wo...</td>\n",
       "      <td>little girl pink dress going wooden cabin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name comment_number  \\\n",
       "11  1000268201.jpg              1   \n",
       "\n",
       "                                              comment  \\\n",
       "11   A little girl in a pink dress going into a wo...   \n",
       "\n",
       "                              cleaned_comment  \n",
       "11  little girl pink dress going wooden cabin  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy['cleaned_comment'] = data_copy['comment'].apply(process_comment)\n",
    "data_copy.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a4d1c9",
   "metadata": {},
   "source": [
    "#### Encode Text for BERT\n",
    "1. Getting the max length of the comments\n",
    "    1. Grab all the comments and store them into a numpy array\n",
    "        - We can do this by using `.values` on a column of a pandas df\n",
    "            - array[('A dog', 'A cat')]\n",
    "    2. `Tokenize` each word\n",
    "        - The `NLTK tokenizer` turns each comment into a sublist of words of the entire comment\n",
    "        - The `BERT tokenizer` turns each word inside of a comment to its own unique integer\n",
    "            - There are special tokens called `cls`, `sep`, `unk`, `pad`, `mask`\n",
    "                - `cls`: tells us when the sentence begins\n",
    "                - `sep`: tells us when the sentence ends\n",
    "                - `unk`: tells us when a word is not in BERT's vocabulary\n",
    "                - `pad`: tells us when a sentence is too short, so we add this token to make it longer\n",
    "                - `mask`: masks a word in the sentence and tries to get the model to predict the word during training\n",
    "   3. Loop through the comments, tokenize each comment, and find the max length of all the sentences because we need to pad the other sentences to this length as an input for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e740c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = data_copy['cleaned_comment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a4d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "579fd4cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in sentences:\n",
    "    input_ids = tokenizer.encode(i, add_special_tokens=True)\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98477f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_ids_masks(text, max_len=64):\n",
    "    tokens = tokenizer.encode_plus(\n",
    "        text,\n",
    "        max_length=max_len,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "    input_ids = tokens['input_ids']\n",
    "    attention_mask = tokens['attention_mask']\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7ac467b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>two young guy shaggy hair look hand hanging yard</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2402), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>two young white male outside near many bush</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2402), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>two men green shirt standing yard</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2273), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>man blue shirt standing garden</td>\n",
       "      <td>[[tensor(101), tensor(2158), tensor(2630), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>two friend enjoy time spent together</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2767), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name comment_number  \\\n",
       "0  1000092795.jpg              0   \n",
       "1  1000092795.jpg              1   \n",
       "2  1000092795.jpg              2   \n",
       "3  1000092795.jpg              3   \n",
       "4  1000092795.jpg              4   \n",
       "\n",
       "                                             comment  \\\n",
       "0   Two young guys with shaggy hair look at their...   \n",
       "1   Two young , White males are outside near many...   \n",
       "2   Two men in green shirts are standing in a yard .   \n",
       "3       A man in a blue shirt standing in a garden .   \n",
       "4            Two friends enjoy time spent together .   \n",
       "\n",
       "                                    cleaned_comment  \\\n",
       "0  two young guy shaggy hair look hand hanging yard   \n",
       "1       two young white male outside near many bush   \n",
       "2                 two men green shirt standing yard   \n",
       "3                    man blue shirt standing garden   \n",
       "4              two friend enjoy time spent together   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [[tensor(101), tensor(2048), tensor(2402), ten...   \n",
       "1  [[tensor(101), tensor(2048), tensor(2402), ten...   \n",
       "2  [[tensor(101), tensor(2048), tensor(2273), ten...   \n",
       "3  [[tensor(101), tensor(2158), tensor(2630), ten...   \n",
       "4  [[tensor(101), tensor(2048), tensor(2767), ten...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "1  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "2  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "3  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  \n",
       "4  [[tensor(1), tensor(1), tensor(1), tensor(1), ...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy['input_ids'], data_copy['attention_mask'] = zip(*data_copy['cleaned_comment'].apply(gen_ids_masks))\n",
    "data_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968ab844",
   "metadata": {},
   "source": [
    "#### Vgg16 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f69ba74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1000344755.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>a man on a ladder cleans a window</td>\n",
       "      <td>man ladder clean window</td>\n",
       "      <td>[[tensor(101), tensor(2158), tensor(10535), te...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name comment_number                             comment  \\\n",
       "19  1000344755.jpg              4   a man on a ladder cleans a window   \n",
       "\n",
       "            cleaned_comment  \\\n",
       "19  man ladder clean window   \n",
       "\n",
       "                                            input_ids  \\\n",
       "19  [[tensor(101), tensor(2158), tensor(10535), te...   \n",
       "\n",
       "                                       attention_mask  \\\n",
       "19  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                           image_path  \n",
       "19  /Users/blakedickerson/image-text-retrieval/fli...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_root_path = f\"{os.getcwd()}/flickr30k_images/\"\n",
    "data_copy['image_path'] = image_root_path + data_copy['image_name']\n",
    "data_copy.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c314218",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = data_copy.at[0, 'image_path']\n",
    "img = Image.open(image_path)\n",
    "display(img)\n",
    "\n",
    "# this cell crashes for me investigate later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dec6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy['vgg16_embeddings'] = None\n",
    "\n",
    "# Create vgg16 model from torchvision and put on GPU\n",
    "vgg16 = vgg16(pretrained=True).to(device)\n",
    "# Get the embeddings by removing the classification layer\n",
    "vgg16 = torch.nn.Sequential(*(list(vgg16.children())[:-1]))\n",
    "# Put in train mode\n",
    "vgg16.eval()\n",
    "\n",
    "# Preprocess images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225],\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Loop over dataset and train on model\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(data_copy)):\n",
    "        image_path = data_copy.at[idx, 'image_path']\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        # Add a batch to the image -> [C, H, W] -> [1, C, H, W]\n",
    "        img_tensor = transform(img).unsqueeze(dim=0).to(device)\n",
    "        embeddings = vgg16(img_tensor)\n",
    "        data_copy.at[idx, 'vgg16_embeddings'] = embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee0391ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>image_path</th>\n",
       "      <th>vgg16_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>two young guy shaggy hair look hand hanging yard</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2402), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name comment_number  \\\n",
       "0  1000092795.jpg              0   \n",
       "\n",
       "                                             comment  \\\n",
       "0   Two young guys with shaggy hair look at their...   \n",
       "\n",
       "                                    cleaned_comment  \\\n",
       "0  two young guy shaggy hair look hand hanging yard   \n",
       "\n",
       "                                           input_ids  \\\n",
       "0  [[tensor(101), tensor(2048), tensor(2402), ten...   \n",
       "\n",
       "                                      attention_mask  \\\n",
       "0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                          image_path  \\\n",
       "0  /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "\n",
       "                                    vgg16_embeddings  \n",
       "0  [[[[1.3359613 1.5481076 1.9946228 1.3696046 0....  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e91343b",
   "metadata": {},
   "source": [
    "#### BERT Embeddings\n",
    "1. Instantiate the pre-trained BERT model and set the training to the GPU using `.to(device)`\n",
    "2. Fine-tune the BERT pre-trained model over the comments\n",
    "    1. Make a new column for the BERT embeddings and set all values to null\n",
    "    2. Loop over the dataset\n",
    "        - Use `torch.no_grad()` because we do not need gradient calculations because we do not need any backpropogation since we do not need a loss function, rather just the embeddings\n",
    "        - Get the input ids at the $i^{th}$ and $j^{th}$ row and column, respectively\n",
    "        - Get the attention mask at the $i^{th}$ and $j^{th}$ row and column, respectively\n",
    "        - Get the output of the BERT model using the inputs `input ids` and `attention mask`\n",
    "        - Get the embeddings, which is the last state of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf034871",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = BertModel.from_pretrained('bert-base-uncased').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b5dcf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_column = 'input_ids'\n",
    "attention_mask_column = 'attention_mask'\n",
    "data_copy['bert_embeddings'] = None\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx in range(len(data_copy)):\n",
    "        input_ids = data_copy.at[idx, input_ids_column].to(device)\n",
    "        attention_mask = data_copy.at[idx, attention_mask_column].to(device)\n",
    "        outputs = bert_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embeddings = outputs.last_hidden_state\n",
    "        data_copy.at[idx, 'bert_embeddings'] = embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2943ff19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>comment_number</th>\n",
       "      <th>comment</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>image_path</th>\n",
       "      <th>vgg16_embeddings</th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Two young guys with shaggy hair look at their...</td>\n",
       "      <td>two young guy shaggy hair look hand hanging yard</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2402), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "      <td>[[[-0.2685596, 0.21052477, -0.08599222, -0.265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Two young , White males are outside near many...</td>\n",
       "      <td>two young white male outside near many bush</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2402), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "      <td>[[[-0.2770078, -0.39967567, -0.2484164, -0.304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men in green shirts are standing in a yard .</td>\n",
       "      <td>two men green shirt standing yard</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2273), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "      <td>[[[-0.18692452, 0.15539032, -0.3427699, 0.0620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A man in a blue shirt standing in a garden .</td>\n",
       "      <td>man blue shirt standing garden</td>\n",
       "      <td>[[tensor(101), tensor(2158), tensor(2630), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "      <td>[[[-0.17712925, -0.0005741473, -0.13430652, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Two friends enjoy time spent together .</td>\n",
       "      <td>two friend enjoy time spent together</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2767), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "      <td>[[[0.055349417, 0.10062032, 0.15722284, 0.1162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Several men in hard hats are operating a gian...</td>\n",
       "      <td>several men hard hat operating giant pulley sy...</td>\n",
       "      <td>[[tensor(101), tensor(2195), tensor(2273), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[[[-0.16020359, 0.27652726, 0.051281925, 0.135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Workers look down from up above on a piece of...</td>\n",
       "      <td>worker look piece equipment</td>\n",
       "      <td>[[tensor(101), tensor(7309), tensor(2298), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[[[-0.045069344, 0.39052594, -0.107470155, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Two men working on a machine wearing hard hats .</td>\n",
       "      <td>two men working machine wearing hard hat</td>\n",
       "      <td>[[tensor(101), tensor(2048), tensor(2273), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[[[-0.11012821, 0.21814653, -0.651759, 0.11333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Four men on top of a tall structure .</td>\n",
       "      <td>four men top tall structure</td>\n",
       "      <td>[[tensor(101), tensor(2176), tensor(2273), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[[[-0.2949568, 0.3480261, -0.21604586, -0.0413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10002456.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>Three men on a large rig .</td>\n",
       "      <td>three men large rig</td>\n",
       "      <td>[[tensor(101), tensor(2093), tensor(2273), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...</td>\n",
       "      <td>[[[-0.35205492, 0.36165425, -0.3777878, -0.112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>A child in a pink dress is climbing up a set ...</td>\n",
       "      <td>child pink dress climbing set stair entry way</td>\n",
       "      <td>[[tensor(101), tensor(2775), tensor(5061), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0.         1.2030164  2.6505694  2.995126 ...</td>\n",
       "      <td>[[[-0.61910987, -0.13747148, -0.19032045, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>A little girl in a pink dress going into a wo...</td>\n",
       "      <td>little girl pink dress going wooden cabin</td>\n",
       "      <td>[[tensor(101), tensor(2210), tensor(2611), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0.         1.2030164  2.6505694  2.995126 ...</td>\n",
       "      <td>[[[-0.53743047, -0.3977078, -0.031628337, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>A little girl climbing the stairs to her play...</td>\n",
       "      <td>little girl climbing stair playhouse</td>\n",
       "      <td>[[tensor(101), tensor(2210), tensor(2611), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0.         1.2030164  2.6505694  2.995126 ...</td>\n",
       "      <td>[[[-0.6990738, 0.059121437, -0.59789765, 0.161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>A little girl climbing into a wooden playhouse</td>\n",
       "      <td>little girl climbing wooden playhouse</td>\n",
       "      <td>[[tensor(101), tensor(2210), tensor(2611), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0.         1.2030164  2.6505694  2.995126 ...</td>\n",
       "      <td>[[[-0.83253396, 0.0114154145, -0.63082814, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1000268201.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>A girl going into a wooden building .</td>\n",
       "      <td>girl going wooden building</td>\n",
       "      <td>[[tensor(101), tensor(2611), tensor(2183), ten...</td>\n",
       "      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n",
       "      <td>/Users/blakedickerson/image-text-retrieval/fli...</td>\n",
       "      <td>[[[[0.         1.2030164  2.6505694  2.995126 ...</td>\n",
       "      <td>[[[-0.4490553, 0.20539004, 0.08507167, -0.0539...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name comment_number  \\\n",
       "0   1000092795.jpg              0   \n",
       "1   1000092795.jpg              1   \n",
       "2   1000092795.jpg              2   \n",
       "3   1000092795.jpg              3   \n",
       "4   1000092795.jpg              4   \n",
       "5     10002456.jpg              0   \n",
       "6     10002456.jpg              1   \n",
       "7     10002456.jpg              2   \n",
       "8     10002456.jpg              3   \n",
       "9     10002456.jpg              4   \n",
       "10  1000268201.jpg              0   \n",
       "11  1000268201.jpg              1   \n",
       "12  1000268201.jpg              2   \n",
       "13  1000268201.jpg              3   \n",
       "14  1000268201.jpg              4   \n",
       "\n",
       "                                              comment  \\\n",
       "0    Two young guys with shaggy hair look at their...   \n",
       "1    Two young , White males are outside near many...   \n",
       "2    Two men in green shirts are standing in a yard .   \n",
       "3        A man in a blue shirt standing in a garden .   \n",
       "4             Two friends enjoy time spent together .   \n",
       "5    Several men in hard hats are operating a gian...   \n",
       "6    Workers look down from up above on a piece of...   \n",
       "7    Two men working on a machine wearing hard hats .   \n",
       "8               Four men on top of a tall structure .   \n",
       "9                          Three men on a large rig .   \n",
       "10   A child in a pink dress is climbing up a set ...   \n",
       "11   A little girl in a pink dress going into a wo...   \n",
       "12   A little girl climbing the stairs to her play...   \n",
       "13    A little girl climbing into a wooden playhouse    \n",
       "14              A girl going into a wooden building .   \n",
       "\n",
       "                                      cleaned_comment  \\\n",
       "0    two young guy shaggy hair look hand hanging yard   \n",
       "1         two young white male outside near many bush   \n",
       "2                   two men green shirt standing yard   \n",
       "3                      man blue shirt standing garden   \n",
       "4                two friend enjoy time spent together   \n",
       "5   several men hard hat operating giant pulley sy...   \n",
       "6                         worker look piece equipment   \n",
       "7            two men working machine wearing hard hat   \n",
       "8                         four men top tall structure   \n",
       "9                                 three men large rig   \n",
       "10      child pink dress climbing set stair entry way   \n",
       "11          little girl pink dress going wooden cabin   \n",
       "12               little girl climbing stair playhouse   \n",
       "13              little girl climbing wooden playhouse   \n",
       "14                         girl going wooden building   \n",
       "\n",
       "                                            input_ids  \\\n",
       "0   [[tensor(101), tensor(2048), tensor(2402), ten...   \n",
       "1   [[tensor(101), tensor(2048), tensor(2402), ten...   \n",
       "2   [[tensor(101), tensor(2048), tensor(2273), ten...   \n",
       "3   [[tensor(101), tensor(2158), tensor(2630), ten...   \n",
       "4   [[tensor(101), tensor(2048), tensor(2767), ten...   \n",
       "5   [[tensor(101), tensor(2195), tensor(2273), ten...   \n",
       "6   [[tensor(101), tensor(7309), tensor(2298), ten...   \n",
       "7   [[tensor(101), tensor(2048), tensor(2273), ten...   \n",
       "8   [[tensor(101), tensor(2176), tensor(2273), ten...   \n",
       "9   [[tensor(101), tensor(2093), tensor(2273), ten...   \n",
       "10  [[tensor(101), tensor(2775), tensor(5061), ten...   \n",
       "11  [[tensor(101), tensor(2210), tensor(2611), ten...   \n",
       "12  [[tensor(101), tensor(2210), tensor(2611), ten...   \n",
       "13  [[tensor(101), tensor(2210), tensor(2611), ten...   \n",
       "14  [[tensor(101), tensor(2611), tensor(2183), ten...   \n",
       "\n",
       "                                       attention_mask  \\\n",
       "0   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "1   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "2   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "3   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "4   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "5   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "6   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "7   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "8   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "9   [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "10  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "11  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "12  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "13  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "14  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n",
       "\n",
       "                                           image_path  \\\n",
       "0   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "1   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "2   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "3   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "4   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "5   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "6   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "7   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "8   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "9   /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "10  /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "11  /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "12  /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "13  /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "14  /Users/blakedickerson/image-text-retrieval/fli...   \n",
       "\n",
       "                                     vgg16_embeddings  \\\n",
       "0   [[[[1.3359613 1.5481076 1.9946228 1.3696046 0....   \n",
       "1   [[[[1.3359613 1.5481076 1.9946228 1.3696046 0....   \n",
       "2   [[[[1.3359613 1.5481076 1.9946228 1.3696046 0....   \n",
       "3   [[[[1.3359613 1.5481076 1.9946228 1.3696046 0....   \n",
       "4   [[[[1.3359613 1.5481076 1.9946228 1.3696046 0....   \n",
       "5   [[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...   \n",
       "6   [[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...   \n",
       "7   [[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...   \n",
       "8   [[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...   \n",
       "9   [[[[0. 0. 0. 0. 0. 0. 0.], [0. 0. 0. 0. 0. 0. ...   \n",
       "10  [[[[0.         1.2030164  2.6505694  2.995126 ...   \n",
       "11  [[[[0.         1.2030164  2.6505694  2.995126 ...   \n",
       "12  [[[[0.         1.2030164  2.6505694  2.995126 ...   \n",
       "13  [[[[0.         1.2030164  2.6505694  2.995126 ...   \n",
       "14  [[[[0.         1.2030164  2.6505694  2.995126 ...   \n",
       "\n",
       "                                      bert_embeddings  \n",
       "0   [[[-0.2685596, 0.21052477, -0.08599222, -0.265...  \n",
       "1   [[[-0.2770078, -0.39967567, -0.2484164, -0.304...  \n",
       "2   [[[-0.18692452, 0.15539032, -0.3427699, 0.0620...  \n",
       "3   [[[-0.17712925, -0.0005741473, -0.13430652, -0...  \n",
       "4   [[[0.055349417, 0.10062032, 0.15722284, 0.1162...  \n",
       "5   [[[-0.16020359, 0.27652726, 0.051281925, 0.135...  \n",
       "6   [[[-0.045069344, 0.39052594, -0.107470155, -0....  \n",
       "7   [[[-0.11012821, 0.21814653, -0.651759, 0.11333...  \n",
       "8   [[[-0.2949568, 0.3480261, -0.21604586, -0.0413...  \n",
       "9   [[[-0.35205492, 0.36165425, -0.3777878, -0.112...  \n",
       "10  [[[-0.61910987, -0.13747148, -0.19032045, 0.12...  \n",
       "11  [[[-0.53743047, -0.3977078, -0.031628337, 0.05...  \n",
       "12  [[[-0.6990738, 0.059121437, -0.59789765, 0.161...  \n",
       "13  [[[-0.83253396, 0.0114154145, -0.63082814, 0.2...  \n",
       "14  [[[-0.4490553, 0.20539004, 0.08507167, -0.0539...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_copy.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f5fe7",
   "metadata": {},
   "source": [
    "## Part 2. \n",
    "In this part we will build two graphs, x & y, respectively, where each node is an image and each edge is determined by its similarity with the node.\n",
    "\n",
    "<br><br>\n",
    "1000 images -> 1000x1000 i,j element is a scalar what is it? The similarity/closeness between i,j -> cosine similarity -> (I*j)/2 for every I,j scalar which gives us a graph with only the vgg information do the same thing for text \n",
    "\n",
    "Match means we have an order of images , If they are not matching the comment and image are not a pair this is what the algorithm solves\n",
    "\n",
    "Phi means they are not connected\n",
    "Straight line/curve line is the same \n",
    "\n",
    "Node attribute -> embedding\n",
    "\n",
    "n_1/e_1 -> diagonal elements represent different types of nodes node attributes over all nodes are the same along with the edges \n",
    "\n",
    "Node -> ordered number of node\n",
    "Edge -> yes if connected, no if not\n",
    "Try non-binary first, then covert to binary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe71cc5",
   "metadata": {},
   "source": [
    "### Step 2.1 \n",
    "Build graph x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7113a16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>vgg16_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1000344755.jpg</td>\n",
       "      <td>[[[[0. 0. 0. 0. 0. 0. 0.], [0.        0.      ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name                                   vgg16_embeddings\n",
       "17  1000344755.jpg  [[[[0. 0. 0. 0. 0. 0. 0.], [0.        0.      ..."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_x_initial = data_copy[['image_name', 'vgg16_embeddings']]\n",
    "graph_x_initial.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe88decf",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = []\n",
    "for idx, row in graph_x_initial.iterrows():\n",
    "    new_matrix = np.array([row['image_name']])\n",
    "    remaining_rows = graph_x_initial.drop(idx)\n",
    "    transposed = remaining_rows['image_name'].values  # Extract values for transpose\n",
    "    new_matrix = np.concatenate((new_matrix, transposed), axis=0)\n",
    "    matrices.append(new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25d868f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000092795.jpg', '1000092795.jpg', '1000092795.jpg',\n",
       "       '1000092795.jpg', '1000092795.jpg', '10002456.jpg', '10002456.jpg',\n",
       "       '10002456.jpg', '10002456.jpg', '10002456.jpg', '1000268201.jpg',\n",
       "       '1000268201.jpg', '1000268201.jpg', '1000268201.jpg',\n",
       "       '1000268201.jpg', '1000344755.jpg', '1000344755.jpg',\n",
       "       '1000344755.jpg', '1000344755.jpg', '1000344755.jpg'], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af0f552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_x(matrix: np.array,\n",
    "                  df: pd.DataFrame,\n",
    "                  ith_row: int,\n",
    "                  jth_col: int):\n",
    "    \"\"\"\n",
    "    Builds the graph of the images\n",
    "    \n",
    "    matrix (np.array): a 2d array of image names\n",
    "    df (pd.DataFrame): an initial graph of image names and their corresponding embeddings\n",
    "    ith_row (int): number of rows in the dataframe\n",
    "    jth_col (int): number of columns in the dataframe\n",
    "    \"\"\"\n",
    "    graph = pd.DataFrame(index=range(len(matrix)), columns=range(len(matrix)))\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        row_embedding = df.loc[i, 'vgg16_embeddings'].reshape(1, -1)\n",
    "        \n",
    "        for j, col in enumerate(row):\n",
    "            column_embedding = df.loc[j, 'vgg16_embeddings'].reshape(1, -1)\n",
    "            similarity = cosine_similarity(row_embedding, column_embedding)[0][0]\n",
    "            graph.loc[i, j] = similarity\n",
    "    \n",
    "    graph.index = [df.loc[idx, 'image_name'] for idx in range(len(matrix))]\n",
    "    graph.columns = [df.loc[idx, 'image_name'] for idx in range(len(matrix))]\n",
    "    \n",
    "    graph = graph.mul((ith_row * jth_col) / 2)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05f05954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>14.951783</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>19.110151</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "      <td>27.236593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             1000092795.jpg 1000092795.jpg 1000092795.jpg 1000092795.jpg  \\\n",
       "10002456.jpg      14.951783      14.951783      14.951783      14.951783   \n",
       "10002456.jpg      14.951783      14.951783      14.951783      14.951783   \n",
       "\n",
       "             1000092795.jpg 10002456.jpg 10002456.jpg 10002456.jpg  \\\n",
       "10002456.jpg      14.951783        200.0        200.0        200.0   \n",
       "10002456.jpg      14.951783        200.0        200.0        200.0   \n",
       "\n",
       "             10002456.jpg 10002456.jpg 1000268201.jpg 1000268201.jpg  \\\n",
       "10002456.jpg        200.0        200.0      19.110151      19.110151   \n",
       "10002456.jpg        200.0        200.0      19.110151      19.110151   \n",
       "\n",
       "             1000268201.jpg 1000268201.jpg 1000268201.jpg 1000344755.jpg  \\\n",
       "10002456.jpg      19.110151      19.110151      19.110151      27.236593   \n",
       "10002456.jpg      19.110151      19.110151      19.110151      27.236593   \n",
       "\n",
       "             1000344755.jpg 1000344755.jpg 1000344755.jpg 1000344755.jpg  \n",
       "10002456.jpg      27.236593      27.236593      27.236593      27.236593  \n",
       "10002456.jpg      27.236593      27.236593      27.236593      27.236593  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_x = build_graph_x(matrix=matrices,\n",
    "                        df=graph_x_initial,\n",
    "                        ith_row=20,\n",
    "                        jth_col=20)\n",
    "graph_x.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5a15f",
   "metadata": {},
   "source": [
    "## Step 2.2\n",
    "Build graph y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5c5d6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000092795.jpg</td>\n",
       "      <td>[[[-0.2685596, 0.21052477, -0.08599222, -0.265...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_name                                    bert_embeddings\n",
       "0  1000092795.jpg  [[[-0.2685596, 0.21052477, -0.08599222, -0.265..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_y_initial = data_copy[['image_name', 'bert_embeddings']]\n",
    "graph_y_initial.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "461f669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrices = []\n",
    "for idx, row in graph_y_initial.iterrows():\n",
    "    new_matrix = np.array([row['image_name']])\n",
    "    remaining_rows = graph_y_initial.drop(idx)\n",
    "    transposed = remaining_rows['image_name'].values  \n",
    "    new_matrix = np.concatenate((new_matrix, transposed), axis=0)\n",
    "    matrices.append(new_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b4fc44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph_y(matrix: np.array,\n",
    "                  df: pd.DataFrame,\n",
    "                  ith_row: int,\n",
    "                  jth_col: int):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    graph = pd.DataFrame(index=range(len(matrix)), columns=range(len(matrix)))\n",
    "    \n",
    "    for i, row in enumerate(matrix):\n",
    "        row_embedding = df.loc[df['image_name'] == row[0], 'bert_embeddings'].values[0].reshape(1, -1)\n",
    "        for j, col in enumerate(row):\n",
    "            column_embedding = df.loc[df['image_name'] == col, 'bert_embeddings'].values[0].reshape(1, -1)\n",
    "            similarity = cosine_similarity(row_embedding, column_embedding)[0][0]\n",
    "            graph.loc[i, j] = similarity\n",
    "            \n",
    "    graph.index = [df.loc[idx, 'image_name'] for idx in range(len(matrix))]\n",
    "    graph.columns = [df.loc[idx, 'image_name'] for idx in range(len(matrix))]\n",
    "    \n",
    "    graph = graph.mul((ith_row * jth_col) / 2)\n",
    "    \n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5b4eb30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>10002456.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <th>1000344755.jpg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>200.000048</td>\n",
       "      <td>200.000048</td>\n",
       "      <td>200.000048</td>\n",
       "      <td>200.000048</td>\n",
       "      <td>200.000048</td>\n",
       "      <td>136.523414</td>\n",
       "      <td>136.523414</td>\n",
       "      <td>136.523414</td>\n",
       "      <td>136.523414</td>\n",
       "      <td>136.523414</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>147.071195</td>\n",
       "      <td>147.071195</td>\n",
       "      <td>147.071195</td>\n",
       "      <td>147.071195</td>\n",
       "      <td>147.071195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <td>199.999821</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>121.723104</td>\n",
       "      <td>135.257769</td>\n",
       "      <td>135.257769</td>\n",
       "      <td>135.257769</td>\n",
       "      <td>135.257769</td>\n",
       "      <td>135.257769</td>\n",
       "      <td>199.999821</td>\n",
       "      <td>199.999821</td>\n",
       "      <td>199.999821</td>\n",
       "      <td>199.999821</td>\n",
       "      <td>149.226141</td>\n",
       "      <td>149.226141</td>\n",
       "      <td>149.226141</td>\n",
       "      <td>149.226141</td>\n",
       "      <td>149.226141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               1000092795.jpg 1000092795.jpg 1000092795.jpg 1000092795.jpg  \\\n",
       "1000092795.jpg     200.000048     200.000048     200.000048     200.000048   \n",
       "1000268201.jpg     199.999821     121.723104     121.723104     121.723104   \n",
       "\n",
       "               1000092795.jpg 10002456.jpg 10002456.jpg 10002456.jpg  \\\n",
       "1000092795.jpg     200.000048   136.523414   136.523414   136.523414   \n",
       "1000268201.jpg     121.723104   121.723104   135.257769   135.257769   \n",
       "\n",
       "               10002456.jpg 10002456.jpg 1000268201.jpg 1000268201.jpg  \\\n",
       "1000092795.jpg   136.523414   136.523414     121.723104     121.723104   \n",
       "1000268201.jpg   135.257769   135.257769     135.257769     199.999821   \n",
       "\n",
       "               1000268201.jpg 1000268201.jpg 1000268201.jpg 1000344755.jpg  \\\n",
       "1000092795.jpg     121.723104     121.723104     121.723104     147.071195   \n",
       "1000268201.jpg     199.999821     199.999821     199.999821     149.226141   \n",
       "\n",
       "               1000344755.jpg 1000344755.jpg 1000344755.jpg 1000344755.jpg  \n",
       "1000092795.jpg     147.071195     147.071195     147.071195     147.071195  \n",
       "1000268201.jpg     149.226141     149.226141     149.226141     149.226141  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_y = build_graph_y(matrix=matrices,\n",
    "                        df=graph_y_initial,\n",
    "                        ith_row=20,\n",
    "                        jth_col=20)\n",
    "graph_y.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052cd42f",
   "metadata": {},
   "source": [
    "## Step 2.3\n",
    "Build adjacency matrix \n",
    "<br>\n",
    "Use a threshold of within 1% of max value of 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81eb31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = pd.DataFrame(np.zeros((len(graph_x), len(graph_y))), index=graph_x.index, columns=graph_y.index)\n",
    "\n",
    "for x_index, x_row in enumerate(graph_x.iterrows()):\n",
    "    largest_indices = np.argsort(x_row[1])[-5:]\n",
    "    A1.iloc[x_index, largest_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "884dade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A2 = pd.DataFrame(np.zeros((len(graph_x), len(graph_y))), index=graph_y.index, columns=graph_x.index)\n",
    "\n",
    "for y_index, y_row in enumerate(graph_y.iterrows()):\n",
    "    largest_indices = np.argsort(y_row[1])[-5:]\n",
    "    A2.iloc[y_index, largest_indices] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "11ac3fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vgg16_embeddings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>[[[[1.3359613 1.5481076 1.9946228 1.3696046 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 vgg16_embeddings\n",
       "image_name                                                       \n",
       "1000092795.jpg  [[[[1.3359613 1.5481076 1.9946228 1.3696046 0...."
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N1 = data_copy[['image_name', 'vgg16_embeddings']]\n",
    "N1 = N1.set_index('image_name')\n",
    "N1.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d26ebf89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert_embeddings</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>[[[-0.2685596, 0.21052477, -0.08599222, -0.265...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>[[[-0.2770078, -0.39967567, -0.2484164, -0.304...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>[[[-0.18692452, 0.15539032, -0.3427699, 0.0620...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>[[[-0.17712925, -0.0005741473, -0.13430652, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000092795.jpg</th>\n",
       "      <td>[[[0.055349417, 0.10062032, 0.15722284, 0.1162...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>[[[-0.16020359, 0.27652726, 0.051281925, 0.135...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>[[[-0.045069344, 0.39052594, -0.107470155, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>[[[-0.11012821, 0.21814653, -0.651759, 0.11333...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>[[[-0.2949568, 0.3480261, -0.21604586, -0.0413...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002456.jpg</th>\n",
       "      <td>[[[-0.35205492, 0.36165425, -0.3777878, -0.112...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <td>[[[-0.61910987, -0.13747148, -0.19032045, 0.12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <td>[[[-0.53743047, -0.3977078, -0.031628337, 0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <td>[[[-0.6990738, 0.059121437, -0.59789765, 0.161...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <td>[[[-0.83253396, 0.0114154145, -0.63082814, 0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000268201.jpg</th>\n",
       "      <td>[[[-0.4490553, 0.20539004, 0.08507167, -0.0539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <td>[[[-0.16639061, 0.30416298, -0.06761111, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <td>[[[-0.12575844, 0.12468723, -0.15983906, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <td>[[[-0.19024302, 0.38836193, 0.04282846, -0.176...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <td>[[[-0.14715265, 0.16165945, -0.40988165, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000344755.jpg</th>\n",
       "      <td>[[[-0.30489913, 0.5038383, -0.1288321, 0.10672...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  bert_embeddings\n",
       "image_name                                                       \n",
       "1000092795.jpg  [[[-0.2685596, 0.21052477, -0.08599222, -0.265...\n",
       "1000092795.jpg  [[[-0.2770078, -0.39967567, -0.2484164, -0.304...\n",
       "1000092795.jpg  [[[-0.18692452, 0.15539032, -0.3427699, 0.0620...\n",
       "1000092795.jpg  [[[-0.17712925, -0.0005741473, -0.13430652, -0...\n",
       "1000092795.jpg  [[[0.055349417, 0.10062032, 0.15722284, 0.1162...\n",
       "10002456.jpg    [[[-0.16020359, 0.27652726, 0.051281925, 0.135...\n",
       "10002456.jpg    [[[-0.045069344, 0.39052594, -0.107470155, -0....\n",
       "10002456.jpg    [[[-0.11012821, 0.21814653, -0.651759, 0.11333...\n",
       "10002456.jpg    [[[-0.2949568, 0.3480261, -0.21604586, -0.0413...\n",
       "10002456.jpg    [[[-0.35205492, 0.36165425, -0.3777878, -0.112...\n",
       "1000268201.jpg  [[[-0.61910987, -0.13747148, -0.19032045, 0.12...\n",
       "1000268201.jpg  [[[-0.53743047, -0.3977078, -0.031628337, 0.05...\n",
       "1000268201.jpg  [[[-0.6990738, 0.059121437, -0.59789765, 0.161...\n",
       "1000268201.jpg  [[[-0.83253396, 0.0114154145, -0.63082814, 0.2...\n",
       "1000268201.jpg  [[[-0.4490553, 0.20539004, 0.08507167, -0.0539...\n",
       "1000344755.jpg  [[[-0.16639061, 0.30416298, -0.06761111, -0.05...\n",
       "1000344755.jpg  [[[-0.12575844, 0.12468723, -0.15983906, -0.02...\n",
       "1000344755.jpg  [[[-0.19024302, 0.38836193, 0.04282846, -0.176...\n",
       "1000344755.jpg  [[[-0.14715265, 0.16165945, -0.40988165, -0.00...\n",
       "1000344755.jpg  [[[-0.30489913, 0.5038383, -0.1288321, 0.10672..."
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2 = data_copy[['image_name', 'bert_embeddings']]\n",
    "N2 = N2.set_index('image_name')\n",
    "N2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "312cf222",
   "metadata": {},
   "source": [
    "Note in the above cell how even though they are the same image, they have different embeddings..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-text-retrieval",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "35b5a13ae704ebbec493086e065459a8876adb295e43bda9fc5f0c814be01bef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
